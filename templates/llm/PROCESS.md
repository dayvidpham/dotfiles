You should read in the process we are following at @~/.aura/context-eng/AGENTS.md @~/.aura/context-eng/CONSTRAINTS.md and @~/.aura/context-eng/PROCESS.md . We need to add a few phases in though.

The main purpose of this is to create an AUDIT TRAIL that is NEVER lost. We should NOT be deleting or destroying information, labels, from any tasks that are created: only creating new ones, updating old ones with comments. Each of the tasks should block the prior ones. So 3 blocks 2 blocks 1. this means `bd dep add {{task id for 3}} {{task id for 2}}`, and `bd dep add {{task id for 2}} {{task id for 1}}`. This should be run e.g. when 2 is about to start after 1, and similarly with 3 after 2.

Thus the flow should go:

1. aura:user:request, they provide a feature request. This is documented in a Beads task. e.g. task-req . The user's request is captured verbatim in this task along with a description. This is labelled with `bd create --labels aura:user:request {{task title}} --description {{user request}} --role architect`
2. aura:user:elicit, where the architect calls `Skill(/aura:architect)`. The architect then creates a User Requirements Elicitation (URE) survey. The architect should ask questions that provide the most clarity, when it comes to what the user envisions. They should start planning backwards to understand the user's end vision, and what interfaces will be needed. Then they should jump to the start, so that they understand what the user needs in an MVP. Then they should ask targeted questions that maximize information on the various dimensions and boundaries of the required engineering space, proceeding until the milestones to get to the end vision are clear. The user should be prompted to respond, with `multiSelect: true`, and there should be a final question to catch anything that was missed. The questions and user responses are captured verbatim in a new task that is labeled via `bd create --labels aura:user:elicit --role architect {{task title}} --description {{elicitation content}} `. Suppoose this results in `task-eli`.
3. aura:plan:proposal, where the architect initiates their first proposal. This is captured in a task, with `bd create --labels aura:plan:proposal,proposal-1 --role architect {{proposal content}}` Suppose this results in `task-prop`.
4. aura:plan:review, three general-purpose Sonnet agents are spawned in parallel. They should be prompted to use `Skill(/aura:reviewer)`, and they should be given the exact command to `bd show {{exact task id for the aura:user:request task}}` and `bd show {{exact task id for the proposal-1 task}}`. Each reviewer should be prompted with a reviewer number (1,2,3), and they should be told to create their review as `bd create --labels aura:plan:reivew,proposal-1:review-{{reviewer id 1,2,3}} {{review content}}`. Steps 3 and 4 loop until all reviewers come to ACCEPT consensus. Then handoff occurs to the supervisor agent. Reviewers MUST reach consensus that all requirements, UAT conditions, user end-vision, MVP scope, and codebase quality, style, and constraints are followed.
5. aura:user:uat, where a User Acceptance Test (UAT) is performed after the reviews reach consensus, to see if the plan aligns with the user's vision and MVP. Several demonstrative examples should be shown with each question, so that the user has an idea for how the interface will be defined, created, used, and how it relates to their requirements. The user should be prompted to respond, with `multiSelect: true`, and there should be a final question to catch anything that was missed. The questions and user responses are captured verbatim in a new task that is labeled via `bd create --labels aura:user:uat,proposal-1:uat-1 {{uat task}}`.
6. aura:plan:ratify, where the architect marks the plan as complete, and they add a label `aura:plan:ratify` to the proposal which reached consensus. 
7. aura:plan:handoff, where we use the python script to spawn a supervisor, prompted with `Skill(/aura:supervisor)` who is prompted to run the exact `bd show {{ratified plan id}} {{user uat}} {{user elicit}}` for the necessary context.
8. aura:impl:plan, where we move onto the implementation phase. For this the supervisor will run `Skill(/aura:supervisor:plan-tasks)`, and decompose the ratified plan into a series of independent, horizontal cake layers of tasks. Afterwards, the supervisor will assign out end-to-end vertical slices of these tasks, which group similar features together. A `bd create --labels aura:impl:plan --description {{short description, contains implementation ideas}} --role supervisor` should be created, and the vertical slices should be created like `bd create --labels aura:impl:slice,slice-{A,B,C,...} --description {{contains detailed implementation tasks}} --role worker`. Maybe we can use the `--assignee` flag too somehow, if appropriate. The supervisor allocates each vertical slices to a worker. Synchronization points between the slices is allowed: but these should be minimized if possible.
9. aura:impl:worker, will be launched in parallel, and they will handle the implementation of each slice. When they begin their work, they call `Skill(aura:worker)`, and they update the task status to in_progress. When their task is completed, they MUST perform the validation steps, the checklist, and double-check against the slice and the implementation plan to see if they are anything.
10. aura:impl:review, once all the slices are complete, the supervisor spawns another supervisor using the launch-parallel.py python script. This supervisor should launch 3 Sonnet agents who will review each slice. So Reviewer 1 will review A, B, C, and Reviewer 2 will review A, B, C, and so on. A review ticket should be made for each slice. Each reviewer will comment on that ticket, for each slice. The MUST reviewers reach consensus that all requirements, UAT conditions, user end-vision, MVP scope, and codebase quality, style, and constraints are followed.
11. aura:impl:uat, the user performs a UAT once all the reviewers reach consensus. They are shown demonstrative examples of each slice, and the same questioning criteria and process is applied as in the prior UATs.
12. If the user accepts the code, then we will begin landing the plane.

You should read in the process we are following at @~/.aura/context-eng/AGENTS.md @~/.aura/context-eng/CONSTRAINTS.md and @~/.aura/context-eng/PROCESS.md . We need to add a few phases in though.

The main purpose of this is to create an AUDIT TRAIL that is NEVER lost. We should NOT be deleting or destroying information, labels, from any tasks that are created: only creating new ones, updating old ones with comments. Each of the tasks should block the prior ones. So 3 blocks 2 blocks 1. this means `bd dep add {{task id for 3}} {{task id for 2}}`, and `bd dep add {{task id for 2}} {{task id for 1}}`. This should be run e.g. when 2 is about to start after 1, and similarly with 3 after 2.

Thus the flow should go:

1. aura:user:request, they provide a feature request. This is documented in a Beads task. e.g. task-req . The user's request is captured verbatim in this task along with a description. This is labelled with `bd create --labels aura:user:request {{task title}} --description {{user request}} --role architect`
2. aura:user:elicit, where the architect calls `Skill(/aura:architect)`. The architect then creates a User Requirements Elicitation (URE) survey. The architect should ask questions that provide the most clarity, when it comes to what the user envisions. They should start planning backwards to understand the user's end vision, and what interfaces will be needed. Then they should jump to the start, so that they understand what the user needs in an MVP. Then they should ask targeted questions that maximize information on the various dimensions and boundaries of the required engineering space, proceeding until the milestones to get to the end vision are clear. The user should be prompted to respond, with `multiSelect: true`, and there should be a final question to catch anything that was missed. The questions and user responses are captured verbatim in a new task that is labeled via `bd create --labels aura:user:elicit --role architect {{task title}} --description {{elicitation content}} `. Suppoose this results in `task-eli`.
3. aura:plan:proposal, where the architect initiates their first proposal. This is captured in a task, with `bd create --labels aura:plan:proposal,proposal-1 --role architect {{proposal content}}` Suppose this results in `task-prop`.
4. aura:plan:review, three general-purpose Sonnet agents are spawned in parallel. They should be prompted to use `Skill(/aura:reviewer)`, and they should be given the exact command to `bd show {{exact task id for the aura:user:request task}}` and `bd show {{exact task id for the proposal-1 task}}`. Each reviewer should be prompted with a reviewer number (1,2,3), and they should be told to create their review as `bd create --labels aura:plan:reivew,proposal-1:review-{{reviewer id 1,2,3}} {{review content}}`. Steps 3 and 4 loop until all reviewers come to ACCEPT consensus. Then handoff occurs to the supervisor agent. Reviewers MUST reach consensus that all requirements, UAT conditions, user end-vision, MVP scope, and codebase quality, style, and constraints are followed.
5. aura:user:uat, where a User Acceptance Test (UAT) is performed after the reviews reach consensus, to see if the plan aligns with the user's vision and MVP. Several demonstrative examples should be shown with each question, so that the user has an idea for how the interface will be defined, created, used, and how it relates to their requirements. The user should be prompted to respond, with `multiSelect: true`, and there should be a final question to catch anything that was missed. The questions and user responses are captured verbatim in a new task that is labeled via `bd create --labels aura:user:uat,proposal-1:uat-1 {{uat task}}`.
6. aura:plan:ratify, where the architect marks the plan as complete, and they add a label `aura:plan:ratify` to the proposal which reached consensus. 
7. aura:plan:handoff, where we use the python script to spawn a supervisor, prompted with `Skill(/aura:supervisor)` who is prompted to run the exact `bd show {{ratified plan id}} {{user uat}} {{user elicit}}` for the necessary context.
8. aura:impl:plan, where we move onto the implementation phase. For this the supervisor will run `Skill(/aura:supervisor:plan-tasks)`, and decompose the ratified plan into a series of independent, horizontal cake layers of tasks. Afterwards, the supervisor will assign out end-to-end vertical slices of these tasks, which group similar features together. A `bd create --labels aura:impl:plan --description {{short description, contains implementation ideas}} --role supervisor` should be created, and the vertical slices should be created like `bd create --labels aura:impl:slice,slice-{A,B,C,...} --description {{contains detailed implementation tasks}} --role worker`. Maybe we can use the `--assignee` flag too somehow, if appropriate. The supervisor allocates each vertical slices to a worker. Synchronization points between the slices is allowed: but these should be minimized if possible.
9. aura:impl:worker, will be launched in parallel, and they will handle the implementation of each slice. When they begin their work, they call `Skill(aura:worker)`, and they update the task status to in_progress. When their task is completed, they MUST perform the validation steps, the checklist, and double-check against the slice and the implementation plan to see if they are anything.
10. aura:impl:review, once all the slices are complete, the supervisor spawns another supervisor using the launch-parallel.py python script. This supervisor should launch 3 Sonnet agents who will review each slice. So Reviewer 1 will review A, B, C, and Reviewer 2 will review A, B, C, and so on. A review ticket should be made for each slice. Each reviewer will comment on that ticket, for each slice. The MUST reviewers reach consensus that all requirements, UAT conditions, user end-vision, MVP scope, and codebase quality, style, and constraints are followed.
11. aura:impl:uat, the user performs a UAT once all the reviewers reach consensus. They are shown demonstrative examples of each slice, and the same questioning criteria and process is applied as in the prior UATs.
12. If the user accepts the code, then we will begin landing the plane.
